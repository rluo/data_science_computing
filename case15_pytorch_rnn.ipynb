{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T16:46:09.631323Z",
     "start_time": "2020-04-19T16:46:09.131244Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:45:34.674007Z",
     "start_time": "2020-04-19T22:45:34.113429Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "usa_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T20:28:28.512025Z",
     "start_time": "2020-04-19T20:28:28.493472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>4/9/20</th>\n",
       "      <th>4/10/20</th>\n",
       "      <th>4/11/20</th>\n",
       "      <th>4/12/20</th>\n",
       "      <th>4/13/20</th>\n",
       "      <th>4/14/20</th>\n",
       "      <th>4/15/20</th>\n",
       "      <th>4/16/20</th>\n",
       "      <th>4/17/20</th>\n",
       "      <th>4/18/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>84090055</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90055.0</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>84090056</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90056.0</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>84099999</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grand Princess</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>84070004</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michigan Department of Corrections (MDOC)</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370</td>\n",
       "      <td>429</td>\n",
       "      <td>472</td>\n",
       "      <td>472</td>\n",
       "      <td>514</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>84070005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Federal Correctional Institution (FCI)</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           UID iso2 iso3  code3     FIPS  \\\n",
       "3250  84090055   US  USA    840  90055.0   \n",
       "3251  84090056   US  USA    840  90056.0   \n",
       "3252  84099999   US  USA    840  99999.0   \n",
       "3253  84070004   US  USA    840      NaN   \n",
       "3254  84070005   US  USA    840      NaN   \n",
       "\n",
       "                                         Admin2  Province_State  \\\n",
       "3250                                 Unassigned       Wisconsin   \n",
       "3251                                 Unassigned         Wyoming   \n",
       "3252                                        NaN  Grand Princess   \n",
       "3253  Michigan Department of Corrections (MDOC)        Michigan   \n",
       "3254     Federal Correctional Institution (FCI)        Michigan   \n",
       "\n",
       "     Country_Region  Lat  Long_  ... 4/9/20  4/10/20  4/11/20  4/12/20  \\\n",
       "3250             US  0.0    0.0  ...      0        0        0        0   \n",
       "3251             US  0.0    0.0  ...      0        0        0        0   \n",
       "3252             US  0.0    0.0  ...    103      103      103      103   \n",
       "3253             US  0.0    0.0  ...      0        0        0        0   \n",
       "3254             US  0.0    0.0  ...      0        0        0        0   \n",
       "\n",
       "      4/13/20  4/14/20  4/15/20  4/16/20  4/17/20  4/18/20  \n",
       "3250        0        1        1        0        0        0  \n",
       "3251        0        0        0        0        0        0  \n",
       "3252      103      103      103      103      103      103  \n",
       "3253      370      429      472      472      514      550  \n",
       "3254       21       23       36       36       44       45  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T19:24:54.926186Z",
     "start_time": "2020-04-19T19:24:54.922985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3255, 99)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T19:25:29.670290Z",
     "start_time": "2020-04-19T19:25:29.665901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
       "       'Country_Region', 'Lat', 'Long_', 'Combined_Key', '1/22/20', '1/23/20',\n",
       "       '1/24/20', '1/25/20', '1/26/20', '1/27/20', '1/28/20', '1/29/20',\n",
       "       '1/30/20', '1/31/20', '2/1/20', '2/2/20', '2/3/20', '2/4/20', '2/5/20',\n",
       "       '2/6/20', '2/7/20', '2/8/20', '2/9/20', '2/10/20', '2/11/20', '2/12/20',\n",
       "       '2/13/20', '2/14/20', '2/15/20', '2/16/20', '2/17/20', '2/18/20',\n",
       "       '2/19/20', '2/20/20', '2/21/20', '2/22/20', '2/23/20', '2/24/20',\n",
       "       '2/25/20', '2/26/20', '2/27/20', '2/28/20', '2/29/20', '3/1/20',\n",
       "       '3/2/20', '3/3/20', '3/4/20', '3/5/20', '3/6/20', '3/7/20', '3/8/20',\n",
       "       '3/9/20', '3/10/20', '3/11/20', '3/12/20', '3/13/20', '3/14/20',\n",
       "       '3/15/20', '3/16/20', '3/17/20', '3/18/20', '3/19/20', '3/20/20',\n",
       "       '3/21/20', '3/22/20', '3/23/20', '3/24/20', '3/25/20', '3/26/20',\n",
       "       '3/27/20', '3/28/20', '3/29/20', '3/30/20', '3/31/20', '4/1/20',\n",
       "       '4/2/20', '4/3/20', '4/4/20', '4/5/20', '4/6/20', '4/7/20', '4/8/20',\n",
       "       '4/9/20', '4/10/20', '4/11/20', '4/12/20', '4/13/20', '4/14/20',\n",
       "       '4/15/20', '4/16/20', '4/17/20', '4/18/20'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T19:28:37.640659Z",
     "start_time": "2020-04-19T19:28:37.635785Z"
    }
   },
   "outputs": [],
   "source": [
    "usa_case_df = usa_df.filter(like='/20' ) # regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T20:35:02.591208Z",
     "start_time": "2020-04-19T20:35:02.581709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.949140021936568, -0.05085997806343206)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_case_arr = usa_case_df.to_numpy()\n",
    "case_max = np.max(usa_case_arr)\n",
    "usa_case_arr = np.log10(1 + usa_case_arr)/np.log10(1 + case_max)\n",
    "case_mean = np.mean(  usa_case_arr )\n",
    "usa_case_arr = usa_case_arr - case_mean\n",
    "np.max(usa_case_arr), np.min(usa_case_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T20:49:56.194989Z",
     "start_time": "2020-04-19T20:49:56.189189Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "day_vec = np.array( [  datetime.datetime.strptime(d, '%m/%d/%y').weekday()  for d in usa_case_df.columns ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T20:39:20.568629Z",
     "start_time": "2020-04-19T20:39:20.566234Z"
    }
   },
   "source": [
    "# Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T21:37:56.570249Z",
     "start_time": "2020-04-19T21:37:56.559199Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pred_no(no_region, no_day):\n",
    "    pred_range = list( range(9, no_day) ) # the 10th day, 7 day input + 3 day ahead\n",
    "    # given i in pred_range, use range( i - 9 : i - 2  ) # 7 days to predict i\n",
    "    no_pred = no_region * len(pred_range)\n",
    "    return no_pred,   pred_range\n",
    "\n",
    "class covid_dataset(Dataset):\n",
    "    def __init__(self,  arr, day_vec):\n",
    "        self.arr = arr\n",
    "        no_region, no_day = arr.shape\n",
    "        no_pred, pred_range = get_pred_no(no_region, no_day)\n",
    "        self.no_region = no_region\n",
    "        self.no_day = no_day\n",
    "        # predict index in days\n",
    "        self.pred_range = pred_range\n",
    "        self.n_len = no_pred\n",
    "        self.day_vec = day_vec\n",
    "    def __len__(self):\n",
    "        return  self.n_len\n",
    "    def __getitem__(self, idx):\n",
    "        # predict 3 day ahead\n",
    "        reg_idx = idx//len(self.pred_range) # region index\n",
    "        day_idx = self.pred_range[ idx %   len(self.pred_range)  ]\n",
    "        \n",
    "        x = torch.tensor( np.concatenate( [self.arr[reg_idx, (day_idx - 9):(day_idx - 2)].reshape(-1, 1),  \n",
    "                                           self.day_vec[(day_idx - 9):(day_idx - 2)].reshape((-1, 1))/7,   \n",
    "                                           np.arange((day_idx - 9), (day_idx - 2)).reshape(-1, 1)/self.no_day ], axis = 1), dtype=torch.float).view( -1,  3)\n",
    "        y = torch.tensor(  self.arr[reg_idx, day_idx], dtype=torch.float).view(-1)\n",
    "        return x, y\n",
    "    \n",
    "def my_collate(batch):\n",
    "    xs,ys  = zip(*batch)\n",
    "    return torch.stack(xs),torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:19:49.659558Z",
     "start_time": "2020-04-19T22:19:49.647282Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "n_sample = usa_case_arr.shape[0]\n",
    "idx = np.random.permutation( n_sample )\n",
    "no_tr = round(n_sample * .6)\n",
    "no_va = round(n_sample * 0.2 )\n",
    "usa_case_arr_tr = usa_case_arr[ :no_tr , :]\n",
    "usa_case_arr_va = usa_case_arr[no_tr: (no_tr + no_va), :]\n",
    "usa_case_arr_te = usa_case_arr[(no_tr + no_va):, :]\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "tr_ds = covid_dataset(usa_case_arr_tr, day_vec)\n",
    "va_ds = covid_dataset(usa_case_arr_va, day_vec)\n",
    "te_ds = covid_dataset(usa_case_arr_te, day_vec)\n",
    "tr_dl = DataLoader(tr_ds,  batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=my_collate)\n",
    "va_dl = DataLoader(va_ds,  batch_size=len(va_ds), shuffle=False, drop_last=False, collate_fn=my_collate)\n",
    "te_dl = DataLoader(te_ds,  batch_size=len(te_ds), shuffle=False, drop_last=False, collate_fn=my_collate)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tr_dl = DeviceDataLoader(tr_dl, device)\n",
    "va_dl = DeviceDataLoader(va_dl, device)\n",
    "te_dl = DeviceDataLoader(te_dl, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:20:06.446002Z",
     "start_time": "2020-04-19T22:20:06.430611Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = next( iter(tr_dl) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:20:07.018902Z",
     "start_time": "2020-04-19T22:20:07.015495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 7, 3])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:20:07.254682Z",
     "start_time": "2020-04-19T22:20:07.251365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:20:16.177252Z",
     "start_time": "2020-04-19T22:20:16.173527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154287"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:20:07.973735Z",
     "start_time": "2020-04-19T22:20:07.970782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1205"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:20:30.083680Z",
     "start_time": "2020-04-19T22:20:30.079745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(te_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T21:08:43.199022Z",
     "start_time": "2020-04-19T21:08:22.918Z"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:14:22.849256Z",
     "start_time": "2020-04-19T22:14:22.839748Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "output_dim = 1 \n",
    "hidden_dim = 4\n",
    "num_layers = 1\n",
    "dropout = 0.5 if num_layers > 1 else 0\n",
    "\n",
    "class rnn_seq2scalar(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, batch_size, num_layers, dropout, rnn_model='gru'):\n",
    "        super(rnn_seq2scalar, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers = num_layers, batch_first = True, dropout=dropout)\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, num_layers = num_layers, batch_first = True, dropout=dropout)\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn_model = rnn_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.rnn_model == 'gru':\n",
    "            _, h_n = self.rnn(x)\n",
    "            h_n = h_n[-1].view(-1, self.hidden_dim)\n",
    "        else:\n",
    "            lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "            if self.num_layers > 1:\n",
    "                h_n = h_n.narrow(0, self.num_layers - 1, 1).view(-1, self.hidden_dim)\n",
    "        ypred = self.fc1( h_n  )\n",
    "        return ypred.view(-1)\n",
    "\n",
    "    \n",
    "model = rnn_seq2scalar(input_dim, hidden_dim, output_dim, batch_size, num_layers, dropout).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:14:23.500096Z",
     "start_time": "2020-04-19T22:14:23.491316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2360,  0.4627,  0.4139],\n",
       "         [-0.3929,  0.2864, -0.4096],\n",
       "         [-0.1732, -0.2209, -0.3831],\n",
       "         [ 0.4124, -0.3919,  0.0720],\n",
       "         [-0.0559,  0.3628,  0.0066],\n",
       "         [ 0.4141, -0.3865, -0.4502],\n",
       "         [-0.1323, -0.4867,  0.3779],\n",
       "         [-0.4063, -0.2893, -0.1291],\n",
       "         [ 0.1879, -0.0672, -0.1819],\n",
       "         [ 0.0485, -0.3925, -0.1920],\n",
       "         [ 0.1578, -0.1727, -0.0711],\n",
       "         [ 0.4360, -0.3341,  0.0584],\n",
       "         [-0.4776, -0.4319, -0.2273],\n",
       "         [-0.3043, -0.0542, -0.4767],\n",
       "         [ 0.1525, -0.2570, -0.3368],\n",
       "         [ 0.1731,  0.3477,  0.1181]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2015, -0.0342,  0.2576, -0.1201],\n",
       "         [-0.3979, -0.3582, -0.3989, -0.2033],\n",
       "         [ 0.1907, -0.0365,  0.2553,  0.0515],\n",
       "         [ 0.1436,  0.3092, -0.3693, -0.1821],\n",
       "         [-0.4706,  0.1698, -0.3658,  0.0457],\n",
       "         [ 0.2029,  0.0898, -0.1253, -0.2499],\n",
       "         [-0.3750, -0.3850,  0.0979, -0.4765],\n",
       "         [-0.0501, -0.2655, -0.4255,  0.2965],\n",
       "         [ 0.0782,  0.2965, -0.0857, -0.4817],\n",
       "         [ 0.1929, -0.0014,  0.1074,  0.4785],\n",
       "         [-0.0990, -0.0290,  0.2305, -0.4566],\n",
       "         [ 0.0194,  0.1160,  0.3296, -0.2794],\n",
       "         [ 0.0626, -0.3546, -0.3549,  0.3910],\n",
       "         [ 0.2825, -0.3731,  0.0156,  0.4309],\n",
       "         [ 0.0306, -0.2531, -0.0285, -0.4500],\n",
       "         [ 0.4167,  0.0117,  0.3799,  0.4899]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1524, -0.2902,  0.1508, -0.2960,  0.4440, -0.3184, -0.3865, -0.0991,\n",
       "         -0.2644, -0.4289, -0.4681,  0.4165,  0.1010, -0.4771, -0.3677,  0.1196],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3338, -0.4296, -0.0423, -0.4680, -0.4799,  0.4993, -0.1677,  0.4379,\n",
       "          0.0279,  0.4590, -0.3472,  0.0646,  0.0151,  0.2229, -0.2365,  0.2862],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.3110, -0.4831,  0.3243],\n",
       "         [ 0.4252,  0.2349, -0.1324],\n",
       "         [-0.0870, -0.3578,  0.2062],\n",
       "         [ 0.2984, -0.3576,  0.1740],\n",
       "         [-0.0219, -0.4707,  0.0994],\n",
       "         [ 0.0861, -0.3067, -0.4638],\n",
       "         [-0.1315,  0.1826, -0.2477],\n",
       "         [ 0.4530,  0.0973,  0.0464],\n",
       "         [ 0.3350,  0.0647,  0.0287],\n",
       "         [ 0.0921,  0.4824,  0.2895],\n",
       "         [ 0.3971, -0.3339, -0.2193],\n",
       "         [-0.1863,  0.2804, -0.4612]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2124, -0.4880,  0.0269,  0.1129],\n",
       "         [-0.4719,  0.1594,  0.3494, -0.3039],\n",
       "         [-0.3620, -0.1453, -0.3542, -0.3583],\n",
       "         [-0.3458,  0.3509,  0.2181, -0.2110],\n",
       "         [ 0.4821,  0.0718, -0.3003,  0.1556],\n",
       "         [ 0.4322,  0.1077,  0.2841,  0.2302],\n",
       "         [ 0.3919, -0.0308, -0.1044,  0.2381],\n",
       "         [ 0.4450, -0.1809,  0.0828, -0.1432],\n",
       "         [-0.3470,  0.0775, -0.1765,  0.4644],\n",
       "         [-0.0591, -0.1890, -0.3274,  0.2158],\n",
       "         [ 0.1770, -0.4818,  0.0905,  0.4679],\n",
       "         [-0.3312,  0.1674, -0.3356,  0.4112]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3620, -0.4104,  0.1300,  0.2536,  0.1535, -0.4004,  0.2432, -0.0831,\n",
       "         -0.4281, -0.1545, -0.1595,  0.0456], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4029, -0.2018, -0.0469, -0.0175,  0.4946,  0.4005,  0.0372,  0.0553,\n",
       "          0.0512,  0.4928, -0.1094, -0.1108], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.4576,  0.0383, -0.4523, -0.0532]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3424], requires_grad=True)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(  model.parameters() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:14:30.874902Z",
     "start_time": "2020-04-19T22:14:30.871094Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:29:24.405384Z",
     "start_time": "2020-04-19T22:28:03.560620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, tr_loss=3.239356, va_loss=0.000496, te_loss=0.000752\n",
      "epoch=1, tr_loss=0.638326, va_loss=0.000453, te_loss=0.000720\n",
      "epoch=2, tr_loss=0.599095, va_loss=0.000453, te_loss=0.000739\n",
      "epoch=3, tr_loss=0.581335, va_loss=0.000430, te_loss=0.000714\n",
      "epoch=4, tr_loss=0.572574, va_loss=0.000424, te_loss=0.000709\n"
     ]
    }
   ],
   "source": [
    "n_epochs= 5\n",
    "\n",
    "def run_epoch(model, n_epochs):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        loss_val = 0\n",
    "        for i, (x, y) in enumerate(tr_dl):\n",
    "            model.zero_grad()\n",
    "            ypred = model(x)\n",
    "            loss = loss_function(ypred.view(-1),  y.view(-1) )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_val += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        va_loss_val = 0\n",
    "        for i, (x, y) in enumerate(va_dl):\n",
    "            ypred = model(x)\n",
    "            loss = loss_function(ypred.view(-1),  y.view(-1) )\n",
    "            va_loss_val += loss.item()\n",
    "\n",
    "\n",
    "        te_loss_val = 0\n",
    "        for i, (x, y) in enumerate(te_dl):\n",
    "            ypred = model(x)\n",
    "            loss = loss_function(ypred.view(-1),  y.view(-1) )\n",
    "            te_loss_val += loss.item()\n",
    "\n",
    "    #     scheduler.step(va_loss_val)\n",
    "        print_str = f'epoch={epoch}, tr_loss={loss_val:.6f}, va_loss={va_loss_val:.6f}, te_loss={te_loss_val:.6f}'\n",
    "        print(print_str)\n",
    "\n",
    "model = rnn_seq2scalar(input_dim, hidden_dim, output_dim, batch_size, num_layers, dropout).to(device)\n",
    "run_epoch(model, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:30:52.730061Z",
     "start_time": "2020-04-19T22:29:24.407741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, tr_loss=11.940415, va_loss=0.000687, te_loss=0.000908\n",
      "epoch=1, tr_loss=0.893565, va_loss=0.000605, te_loss=0.000845\n",
      "epoch=2, tr_loss=0.777006, va_loss=0.000529, te_loss=0.000785\n",
      "epoch=3, tr_loss=0.669499, va_loss=0.000516, te_loss=0.000804\n",
      "epoch=4, tr_loss=0.590504, va_loss=0.000430, te_loss=0.000725\n"
     ]
    }
   ],
   "source": [
    "model = rnn_seq2scalar(input_dim, hidden_dim, output_dim, batch_size, num_layers, dropout, rnn_model='lstm').to(device)\n",
    "run_epoch(model, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:33:44.117043Z",
     "start_time": "2020-04-19T22:33:31.893924Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "tr_dl = DeviceDataLoader(tr_dl, device)\n",
    "va_dl = DeviceDataLoader(va_dl, device)\n",
    "te_dl = DeviceDataLoader(te_dl, device)\n",
    "\n",
    "\n",
    "def convert_dl_to_x_y(dl):\n",
    "    x_list=[]\n",
    "    y_list=[]\n",
    "    for i, (x, y) in enumerate(dl):\n",
    "        x_list.append( x.numpy().reshape((-1, 3*7)) )\n",
    "        y_list.append( y.numpy() )\n",
    "    return np.row_stack(x_list), np.row_stack(y_list)\n",
    "    \n",
    "X_tr, y_tr = convert_dl_to_x_y(tr_dl)\n",
    "X_va, y_va = convert_dl_to_x_y(va_dl)\n",
    "X_te, y_te = convert_dl_to_x_y(te_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:33:55.151684Z",
     "start_time": "2020-04-19T22:33:55.147889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154240, 21), (154240, 1))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T22:38:12.912668Z",
     "start_time": "2020-04-19T22:37:51.403067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_loss=0.000392, va_loss=0.000352, te_loss=0.000681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def run_rf():\n",
    "    regr = RandomForestRegressor(n_estimators = 100, max_depth=5, random_state=0)\n",
    "    regr.fit(X_tr, y_tr.flatten())\n",
    "    \n",
    "    tr_loss = mean_squared_error( regr.predict(X_tr), y_tr.flatten()   )\n",
    "    va_loss = mean_squared_error( regr.predict(X_va), y_va.flatten()   )\n",
    "    te_loss = mean_squared_error( regr.predict(X_te), y_te.flatten()   )\n",
    "    \n",
    "    print_str = f'tr_loss={tr_loss:.6f}, va_loss={va_loss:.6f}, te_loss={te_loss:.6f}'\n",
    "    print(print_str)\n",
    "\n",
    "run_rf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('pyr': conda)",
   "language": "python",
   "name": "python37364bitpyrconda45b5210c788940838c352579c0058f49"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
